{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ja-pa/ea-openai-evals/blob/main/OAI_evals_edit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval tests\n"
      ],
      "metadata": {
        "id": "oZ9kfL5_S22d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OpenAI API key\n",
        "\n",
        "\n",
        "openai_key = '' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "8mJu5OHUTAps",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup and dependecies\n",
        "\n",
        "!git clone https://github.com/ja-pa/evals.git\n",
        "!cd evals && git checkout match_example\n",
        "!cd evals && git lfs fetch --all && git lfs pull\n",
        "#!cat evals/evals/registry/data/logic/samples.jsonl\n",
        "!cd evals && pip install -e .\n",
        "!pip install -q gradio\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import data_table\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "def display_table_from_file(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Parse each line as a JSON object\n",
        "            json_line = json.loads(line)\n",
        "\n",
        "            # Initialize content variables for different roles\n",
        "            system_content = None\n",
        "            user_content = None\n",
        "\n",
        "            # Loop through 'input' list and extract 'content' for each 'role'\n",
        "            for input_dict in json_line['input']:\n",
        "                if input_dict['role'] == 'system':\n",
        "                    system_content = input_dict['content']\n",
        "                elif input_dict['role'] == 'user':\n",
        "                    user_content = input_dict['content']\n",
        "\n",
        "            # Extract 'ideal' field\n",
        "            ideal = json_line['ideal']\n",
        "\n",
        "            # Append to data list\n",
        "            data.append({'System Content': system_content, 'User Content': user_content, 'Ideal': ideal})\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "def get_latest_file(path, pattern):\n",
        "    list_of_files = glob.glob(os.path.join(path, pattern))\n",
        "    if not list_of_files:\n",
        "        return None\n",
        "    latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    return latest_file\n",
        "\n",
        "\n",
        "#log_output=\"/tmp/evallogs/230530205047OSMJXQ5A_gpt-3.5-turbo_logic-fact.jsonl\"\n",
        "def print_log(log_output):\n",
        "  with open(log_output,\"r\") as fp:\n",
        "    for line in fp.readlines():\n",
        "      json_object = json.loads(line)\n",
        "      json_formatted_str = json.dumps(json_object, indent=2)\n",
        "      print(json_formatted_str)\n",
        "\n",
        "\n",
        "def append_line_to_file(file_path, line):\n",
        "    with open(file_path, 'a') as file:\n",
        "        file.write(line + '\\n')\n",
        "\n",
        "# usage example\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def print_jsonl_table(filepath):\n",
        "    # Read the jsonl file\n",
        "    with open(filepath, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Parse each line as json\n",
        "    data = [json.loads(line) for line in lines if line.strip()]\n",
        "\n",
        "    # Merge data based on run_id and sample_id\n",
        "    merged_data = {}\n",
        "    for d in data:\n",
        "        if 'run_id' in d and 'sample_id' in d:\n",
        "            key = (d[\"run_id\"], d[\"sample_id\"])\n",
        "            if key not in merged_data:\n",
        "                merged_data[key] = d\n",
        "            else:\n",
        "                merged_data[key]['data'].update(d['data'])\n",
        "\n",
        "    # Convert the merged data into a list of dictionaries\n",
        "    data_list = list(merged_data.values())\n",
        "\n",
        "    # Create a pandas dataframe from the data\n",
        "    df = pd.DataFrame(data_list)\n",
        "\n",
        "    # Explode the 'data' column into separate columns\n",
        "    df = pd.concat([df.drop(['data'], axis=1), df['data'].apply(pd.Series)], axis=1)\n",
        "\n",
        "    # Split 'prompt' into 'system' and 'user' columns\n",
        "    df['system_prompt'] = df['prompt'].apply(lambda x: x[0]['content'] if x else None)\n",
        "    df['user_prompt'] = df['prompt'].apply(lambda x: x[1]['content'] if x else None)\n",
        "    df = df.drop('prompt', axis=1)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    df = df.drop(['event_id', 'run_id', 'type', 'created_by'], axis=1)\n",
        "\n",
        "    # Reorder columns\n",
        "    df = df[['sample_id', 'created_at', 'system_prompt', 'user_prompt', 'expected', 'sampled', 'picked', 'correct']]\n",
        "\n",
        "    # Display the dataframe\n",
        "    display(df)\n",
        "\n",
        "\n",
        "def add_custom_eval(description, eval, idea, output_file):\n",
        "    textik='{\"input\": [{\"role\": \"system\", \"content\": \"%s\"}, {\"role\": \"user\", \"content\": \"%s\"}], \"ideal\": \"%s\"}'\n",
        "    filled_textik=textik % (description,eval,idea)\n",
        "    append_line_to_file(\"evals/evals/registry/data/test_match/samples.jsonl\", filled_textik)\n",
        "    return filled_textik\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=add_custom_eval, \n",
        "    inputs=[gr.inputs.Textbox(lines=4, label=\"Content description\"),\n",
        "            gr.inputs.Textbox(lines=4, label=\"Eval\"),\n",
        "            gr.inputs.Textbox(lines=4, label=\"Ideal\")\n",
        "            ], \n",
        "    outputs=[gr.outputs.Textbox(label=\"Output Textbox 1\")],\n",
        "    description=\"Add content description, eval and ideal output\"\n",
        ")\n",
        "\n",
        "#eval_name=\"test-match-custom\"\n",
        "#eval_dir_name=\"test_match\"\n",
        "#eval_sample_name=eva_dir_name+\"/samples.jsonl\"\n"
      ],
      "metadata": {
        "id": "zg9qgkzUVX4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b944c03a-807c-497e-fde9-3447b8ef0f41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'evals'...\n",
            "remote: Enumerating objects: 2926, done.\u001b[K\n",
            "remote: Counting objects: 100% (1332/1332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (272/272), done.\u001b[K\n",
            "remote: Total 2926 (delta 1186), reused 1060 (delta 1060), pack-reused 1594\u001b[K\n",
            "Receiving objects: 100% (2926/2926), 1.50 MiB | 7.94 MiB/s, done.\n",
            "Resolving deltas: 100% (1554/1554), done.\n",
            "Filtering content: 100% (258/258), 339.24 MiB | 45.16 MiB/s, done.\n",
            "Branch 'match_example' set up to track remote branch 'match_example' from 'origin'.\n",
            "Switched to a new branch 'match_example'\n",
            "fetch: 273 object(s) found, done.\n",
            "fetch: Fetching all references...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/evals\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mypy (from evals==1.0.3.post1)\n",
            "  Downloading mypy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=0.27.2 (from evals==1.0.3.post1)\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from evals==1.0.3.post1)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blobfile (from evals==1.0.3.post1)\n",
            "  Downloading blobfile-2.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from evals==1.0.3.post1)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (1.22.4)\n",
            "Collecting snowflake-connector-python[pandas] (from evals==1.0.3.post1)\n",
            "  Downloading snowflake_connector_python-3.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (1.5.3)\n",
            "Collecting datasets (from evals==1.0.3.post1)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from evals==1.0.3.post1)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (1.10.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (4.65.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (3.12.0)\n",
            "Collecting mock (from evals==1.0.3.post1)\n",
            "  Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n",
            "Collecting langdetect (from evals==1.0.3.post1)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (2.3.0)\n",
            "Collecting lz4 (from evals==1.0.3.post1)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd (from evals==1.0.3.post1)\n",
            "  Downloading pyzstd-0.15.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.3/399.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (6.0)\n",
            "Collecting sacrebleu (from evals==1.0.3.post1)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from evals==1.0.3.post1) (3.7.1)\n",
            "Collecting setuptools-scm (from evals==1.0.3.post1)\n",
            "  Downloading setuptools_scm-7.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.2->evals==1.0.3.post1) (2.27.1)\n",
            "Collecting aiohttp (from openai>=0.27.2->evals==1.0.3.post1)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex~=3.8 (from blobfile->evals==1.0.3.post1)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->evals==1.0.3.post1) (1.26.15)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->evals==1.0.3.post1) (4.9.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->evals==1.0.3.post1) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->evals==1.0.3.post1)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->evals==1.0.3.post1)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->evals==1.0.3.post1)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->evals==1.0.3.post1) (2023.4.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets->evals==1.0.3.post1)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->evals==1.0.3.post1) (23.1)\n",
            "Collecting responses<0.19 (from datasets->evals==1.0.3.post1)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->evals==1.0.3.post1) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evals==1.0.3.post1) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10 in /usr/local/lib/python3.10/dist-packages (from mypy->evals==1.0.3.post1) (4.5.0)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy->evals==1.0.3.post1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->evals==1.0.3.post1) (2.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->evals==1.0.3.post1) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->evals==1.0.3.post1) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->evals==1.0.3.post1) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evals==1.0.3.post1) (2022.7.1)\n",
            "Collecting portalocker (from sacrebleu->evals==1.0.3.post1)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->evals==1.0.3.post1) (0.8.10)\n",
            "Collecting colorama (from sacrebleu->evals==1.0.3.post1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->evals==1.0.3.post1) (67.7.2)\n",
            "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (1.15.1)\n",
            "Requirement already satisfied: cryptography<41.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (40.0.2)\n",
            "Collecting oscrypto<2.0.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyOpenSSL<24.0.0,>=16.2.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt<3.0.0 (from snowflake-connector-python[pandas]->evals==1.0.3.post1)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (2022.12.7)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]->evals==1.0.3.post1) (2.4.0)\n",
            "Collecting pyarrow>=8.0.0 (from datasets->evals==1.0.3.post1)\n",
            "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]->evals==1.0.3.post1) (2.21)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.2->evals==1.0.3.post1) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai>=0.27.2->evals==1.0.3.post1)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai>=0.27.2->evals==1.0.3.post1)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai>=0.27.2->evals==1.0.3.post1)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai>=0.27.2->evals==1.0.3.post1)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai>=0.27.2->evals==1.0.3.post1)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: evals, fire, langdetect\n",
            "  Building editable for evals (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for evals: filename=evals-1.0.3.post1-0.editable-py3-none-any.whl size=5917 sha256=bc9da617730de62eacf9ba6de917e307b69acef0d12ca98f19b03e0ca4325f76\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ou4czo7o/wheels/81/f0/4a/034257e4ea0b6a82c749ffe52ef2691e7643ddf58d3c98d5b6\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=f7f1593f072625d657fd72932f440472bc188c089c5ea2794ed46097095afb6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=985dff1267e5d2101247e1d803b596220f5f7869177d42a6bdad38549ebc8aee\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built evals fire langdetect\n",
            "Installing collected packages: asn1crypto, xxhash, setuptools-scm, pyzstd, pyjwt, pycryptodomex, pyarrow, portalocker, oscrypto, mypy-extensions, multidict, mock, lz4, langdetect, frozenlist, fire, dill, colorama, backoff, async-timeout, yarl, tiktoken, sacrebleu, responses, mypy, multiprocess, huggingface-hub, blobfile, aiosignal, pyOpenSSL, aiohttp, snowflake-connector-python, openai, datasets, evals\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 asn1crypto-1.5.1 async-timeout-4.0.2 backoff-2.2.1 blobfile-2.0.2 colorama-0.4.6 datasets-2.12.0 dill-0.3.6 evals-1.0.3.post1 fire-0.5.0 frozenlist-1.3.3 huggingface-hub-0.15.1 langdetect-1.0.9 lz4-4.3.2 mock-5.0.2 multidict-6.0.4 multiprocess-0.70.14 mypy-1.3.0 mypy-extensions-1.0.0 openai-0.27.7 oscrypto-1.3.0 portalocker-2.7.0 pyOpenSSL-23.2.0 pyarrow-10.0.1 pycryptodomex-3.18.0 pyjwt-2.7.0 pyzstd-0.15.7 responses-0.18.0 sacrebleu-2.3.1 setuptools-scm-7.1.0 snowflake-connector-python-3.0.4 tiktoken-0.4.0 xxhash-3.2.0 yarl-1.9.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:758: UserWarning: Expected 4 arguments for function <function add_custom_eval at 0x7fb9c3984af0>, received 3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:762: UserWarning: Expected at least 4 arguments for function <function add_custom_eval at 0x7fb9c3984af0>, received 3.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval\n",
        "Add, show eval, run, show output log"
      ],
      "metadata": {
        "id": "Hl6q-TgItrDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Eval add form\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "Co-5MRA9xw6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "e157f6c4-146c-4849-dcc5-fd4dfdd0333c",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show table with tested evals\n",
        "#df = display_table_from_file('evals/evals/registry/data/test_match/samples.jsonl')\n",
        "#display(df)\n",
        "!cat evals/evals/registry/data/test_match/samples.jsonl\n",
        "#!cat evals/evals/registry/data/logic/samples.jsonl"
      ],
      "metadata": {
        "id": "aZnQTUFThfq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac96cca0-5735-4b17-9bbf-ca49e65f3207"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"input\": [{\"role\": \"system\", \"content\": \"Complete the phrase as concisely as possible.\"}, {\"role\": \"user\", \"content\": \"Once upon a \"}], \"ideal\": \"time\"}\n",
            "{\"input\": [{\"role\": \"system\", \"content\": \"Complete the phrase as concisely as possible.\"}, {\"role\": \"user\", \"content\": \"The first US president was \"}], \"ideal\": \"George Washington\"}\n",
            "{\"input\": [{\"role\": \"system\", \"content\": \"Complete the phrase as concisely as possible.\"}, {\"role\": \"user\", \"content\": \"OpenAI was founded in 20\"}], \"ideal\": \"15\"}\n",
            "{\"input\": [{\"role\": \"system\", \"content\": \"Complete the phrase as concisely as possible\"}, {\"role\": \"user\", \"content\": \"Prague is capital of\"}], \"ideal\": \"Czech Republic\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JVNCSi1lIW7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c578615d-53d6-4ff0-d7ba-310c41401f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-06-06 16:32:22,883] [registry.py:250] Loading registry from /content/evals/evals/registry/evals\n",
            "[2023-06-06 16:32:23,215] [registry.py:250] Loading registry from /root/.evals/evals\n",
            "[2023-06-06 16:32:23,217] [oaieval.py:110] \u001b[1;35mRun started: 2306061632232VOTIT6E\u001b[0m\n",
            "[2023-06-06 16:32:23,218] [data.py:75] Fetching test_match/samples.jsonl\n",
            "[2023-06-06 16:32:23,218] [eval.py:33] Evaluating 5 samples\n",
            "[2023-06-06 16:32:23,223] [eval.py:138] Running in threaded mode with 10 threads!\n",
            "100% 5/5 [00:01<00:00,  3.34it/s]\n",
            "[2023-06-06 16:32:24,729] [record.py:341] Final report: {'accuracy': 0.8}. Logged to /tmp/evallogs/2306061632232VOTIT6E_gpt-3.5-turbo_test-match-custom.jsonl\n",
            "[2023-06-06 16:32:24,729] [oaieval.py:147] Final report:\n",
            "[2023-06-06 16:32:24,729] [oaieval.py:149] accuracy: 0.8\n",
            "[2023-06-06 16:32:24,731] [record.py:330] Logged 10 rows of events to /tmp/evallogs/2306061632232VOTIT6E_gpt-3.5-turbo_test-match-custom.jsonl: insert_time=0.992ms\n"
          ]
        }
      ],
      "source": [
        "#@title Run eval\n",
        "\n",
        "!cd evals && OPENAI_API_KEY=$openai_key oaieval gpt-3.5-turbo test-match-custom\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show eval output log\n",
        "\n",
        "# Call the function with your JSONL file path\n",
        "#print_jsonl_table('your_file.jsonl')\n",
        "\n",
        "\n",
        "log_output=get_latest_file(\"/tmp/evallogs\", \"*gpt-3.5-turbo_test-match-custom.jsonl\")\n",
        "\n",
        "print(log_output)\n",
        "print_jsonl_table(log_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "cellView": "form",
        "id": "u8edBegeRxvF",
        "outputId": "042617cf-a3af-4a95-a251-8c968973782b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/evallogs/2306061632232VOTIT6E_gpt-3.5-turbo_test-match-custom.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                sample_id                        created_at  \\\n",
              "0  test-match-custom.s1.2  2023-06-06 16:32:23.965931+00:00   \n",
              "1  test-match-custom.s1.1  2023-06-06 16:32:24.046020+00:00   \n",
              "2  test-match-custom.s1.0  2023-06-06 16:32:24.121877+00:00   \n",
              "3  test-match-custom.s1.3  2023-06-06 16:32:24.345351+00:00   \n",
              "4  test-match-custom.s1.4  2023-06-06 16:32:24.727033+00:00   \n",
              "\n",
              "                                   system_prompt                  user_prompt  \\\n",
              "0  Complete the phrase as concisely as possible.     OpenAI was founded in 20   \n",
              "1  Complete the phrase as concisely as possible.  The first US president was    \n",
              "2  Complete the phrase as concisely as possible.                 Once upon a    \n",
              "3   Complete the phrase as concisely as possible         Prague is capital of   \n",
              "4   Complete the phrase as concisely as possible                Prague is not   \n",
              "\n",
              "            expected               sampled             picked  correct  \n",
              "0                 15                   15.                 15     True  \n",
              "1  George Washington    George Washington.  George Washington     True  \n",
              "2               time                 time.               time     True  \n",
              "3     Czech Republic       Czech Republic.     Czech Republic     True  \n",
              "4               Brno  Prague is not Paris.               None    False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d08e97c-3bfe-4d70-acf2-6c184353a694\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>system_prompt</th>\n",
              "      <th>user_prompt</th>\n",
              "      <th>expected</th>\n",
              "      <th>sampled</th>\n",
              "      <th>picked</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test-match-custom.s1.2</td>\n",
              "      <td>2023-06-06 16:32:23.965931+00:00</td>\n",
              "      <td>Complete the phrase as concisely as possible.</td>\n",
              "      <td>OpenAI was founded in 20</td>\n",
              "      <td>15</td>\n",
              "      <td>15.</td>\n",
              "      <td>15</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test-match-custom.s1.1</td>\n",
              "      <td>2023-06-06 16:32:24.046020+00:00</td>\n",
              "      <td>Complete the phrase as concisely as possible.</td>\n",
              "      <td>The first US president was</td>\n",
              "      <td>George Washington</td>\n",
              "      <td>George Washington.</td>\n",
              "      <td>George Washington</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test-match-custom.s1.0</td>\n",
              "      <td>2023-06-06 16:32:24.121877+00:00</td>\n",
              "      <td>Complete the phrase as concisely as possible.</td>\n",
              "      <td>Once upon a</td>\n",
              "      <td>time</td>\n",
              "      <td>time.</td>\n",
              "      <td>time</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test-match-custom.s1.3</td>\n",
              "      <td>2023-06-06 16:32:24.345351+00:00</td>\n",
              "      <td>Complete the phrase as concisely as possible</td>\n",
              "      <td>Prague is capital of</td>\n",
              "      <td>Czech Republic</td>\n",
              "      <td>Czech Republic.</td>\n",
              "      <td>Czech Republic</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test-match-custom.s1.4</td>\n",
              "      <td>2023-06-06 16:32:24.727033+00:00</td>\n",
              "      <td>Complete the phrase as concisely as possible</td>\n",
              "      <td>Prague is not</td>\n",
              "      <td>Brno</td>\n",
              "      <td>Prague is not Paris.</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d08e97c-3bfe-4d70-acf2-6c184353a694')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d08e97c-3bfe-4d70-acf2-6c184353a694 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d08e97c-3bfe-4d70-acf2-6c184353a694');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}